{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql as sparksql\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "spark = SparkSession.builder.appName('titanic').getOrCreate()\n",
    "\n",
    "train = spark.read.csv('/home/ravisankar/Desktop/datasets/titanic/train.csv', inferSchema=True,header=True)\n",
    "train_pd=pd.read_csv('/home/ravisankar/Desktop/datasets/titanic/train.csv')\n",
    "train_shape=train_pd.shape\n",
    "print(train_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('titanic_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----------------+\n",
      "|   Sex|gender_count|          percent|\n",
      "+------+------------+-----------------+\n",
      "|female|         314|35.24130190796858|\n",
      "|  male|         577|64.75869809203142|\n",
      "+------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Sex ,count(Sex) as gender_count,count(sex)*100/sum(count(sex)) over() as percent from titanic_table GROUP BY Sex\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------------------+\n",
      "|   Sex|gender_count|           percent|\n",
      "+------+------------+------------------+\n",
      "|female|         233| 68.12865497076024|\n",
      "|  male|         109|31.871345029239766|\n",
      "+------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Sex, count(Sex) AS gender_count, \\\n",
    "100*count(sex)/sum(count(sex)) over() AS percent \\\n",
    "FROM titanic_table \\\n",
    "WHERE Survived = 1 \\\n",
    "GROUP BY sex\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------------------+\n",
      "|   Sex|gender_count|           percent|\n",
      "+------+------------+------------------+\n",
      "|female|         233| 68.12865497076024|\n",
      "|  male|         109|31.871345029239766|\n",
      "+------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Sex, count(Sex) AS gender_count, \\\n",
    "100*count(sex)/sum(count(sex)) over() AS percent \\\n",
    "FROM titanic_table \\\n",
    "WHERE Survived = 1 \\\n",
    "GROUP BY sex\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-----------------+\n",
      "|Pclass|class_count|          percent|\n",
      "+------+-----------+-----------------+\n",
      "|     1|        136|39.76608187134503|\n",
      "|     3|        119| 34.7953216374269|\n",
      "|     2|         87|25.43859649122807|\n",
      "+------+-----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"SELECT Pclass, count(Pclass) as class_count,\\\n",
    "         count(Pclass)*100/sum(count(Pclass)) over() AS percent \\\n",
    "         FROM titanic_table \\\n",
    "         WHERE Survived=1 GROUP BY Pclass\").show()\n",
    "import matplotlib.pyplot as plt\n",
    "sex_table=train_pd.pivot_table(index=\"Pclass\",values=\"Survived\")\n",
    "sex_table.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "| Age|age_count|\n",
      "+----+---------+\n",
      "|24.0|       15|\n",
      "|22.0|       11|\n",
      "|36.0|       11|\n",
      "|27.0|       11|\n",
      "|35.0|       11|\n",
      "|30.0|       10|\n",
      "|32.0|        9|\n",
      "|19.0|        9|\n",
      "|18.0|        9|\n",
      "|29.0|        8|\n",
      "|31.0|        8|\n",
      "|28.0|        7|\n",
      "| 4.0|        7|\n",
      "|48.0|        6|\n",
      "|17.0|        6|\n",
      "|42.0|        6|\n",
      "|25.0|        6|\n",
      "|40.0|        6|\n",
      "|34.0|        6|\n",
      "|33.0|        6|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Age, count(Age) as age_count FROM titanic_table WHERE Survived == 1 GROUP BY Age ORDER BY age_count DESC\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.filter((train['Survived']==1)&(train['Age']>='14')).count()\n",
    "train.filter((train['Survived']==1)&(train['Sex']=='female')&(train['Age']>=14)).count()\n",
    "#train.filter((train['Survived']==1)&(train['Age']>='14')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "mean = train.select(mean(train['Age'])).collect()\n",
    "mean_age = mean[0][0]\n",
    "train = train.na.fill(mean_age,['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,OneHotEncoder,\n",
    "                                StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex_indexer=StringIndexer(inputCol='Sex',outputCol='Sexindex')\n",
    "Sex_encoder=OneHotEncoder(inputCol='Sexindex',outputCol='Sexvector')\n",
    "\n",
    "Pclass_indexer=StringIndexer(inputCol='Pclass',outputCol='Pclassindex')\n",
    "Pclass_encoder=OneHotEncoder(inputCol='Pclassindex',outputCol='Pclassvector')\n",
    "\n",
    "Age_indexer=StringIndexer(inputCol='Age',outputCol='Ageindex')\n",
    "Age_encoder=OneHotEncoder(inputCol='Ageindex',outputCol='Agevector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=['PassengerId','Embarked','Pclassvector','Name','Sexvector','Agevector','SibSp','Parch','Ticket','Fare','Cabin'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(labelCol='Survived',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[Sex_indexer, Pclass_indexer, Age_indexer, Sex_encoder,\n",
    "                           Pclass_encoder, Age_encoder, assembler, dtc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Data type string of column Embarked is not supported.\\nData type string of column Name is not supported.\\nData type string of column Ticket is not supported.\\nData type string of column Cabin is not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1153.transform.\n: java.lang.IllegalArgumentException: Data type string of column Embarked is not supported.\nData type string of column Name is not supported.\nData type string of column Ticket is not supported.\nData type string of column Cabin is not supported.\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:169)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:86)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-49495b6949aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtc_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Data type string of column Embarked is not supported.\\nData type string of column Name is not supported.\\nData type string of column Ticket is not supported.\\nData type string of column Cabin is not supported.'"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_data)\n",
    "dtc_predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtc_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-f57d704eff27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdtc_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtc_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A Decision Tree algorithm had an accuracy of: {0:2.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtc_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtc_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "\n",
    "print('A Decision Tree algorithm had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
